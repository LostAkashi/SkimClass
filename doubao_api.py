import os
import time
import base64
import json
import requests
import urllib3
from openai import OpenAI
# 1. ä¿æŒæš´åŠ›è”ç½‘ (ä¸ºäº†å‘å›¾ç‰‡)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ================= ğŸ”‘ å¯†é’¥é…ç½® (ä¿æŒä¸å˜) =================
ASR_APPID = "YOUR_APP_ID_HERE"        
ASR_TOKEN = "YOUR_TOKEN_HERE"
ASR_CLUSTER = "OUR_CLUSTER_ID_HERE"

LLM_API_KEY = "YOUR_API_KEY_HERE"
LLM_ENDPOINT = "YOUR_ENDPOINT_ID_HERE"
# ==========================================================

class DoubaoClient:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=LLM_API_KEY,
            base_url="https://ark.cn-beijing.volces.com/api/v3",
        )

    def audio_to_text(self, file_path):
        # ç³»ç»Ÿâ€œé»˜è®¤â€è¿›å…¥çº¯è§†è§‰æ¨¡å¼ã€‚
        print("âš ï¸ è¿›å…¥è§†è§‰åˆ†ææ¨¡å¼...")
        return "" 

    def generate_report(self, text_context, image_paths=[]):
        print("ğŸ§  æ­£åœ¨æ ¹æ®ã€Šç«‹é¡¹æŠ¥å‘Šã€‹æ ‡å‡†ç”Ÿæˆå«ä¹ é¢˜çš„æŠ¥å‘Š...")
        
        system_prompt = """
        ä½ æ˜¯ç”±å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦å­¦ç”Ÿå¼€å‘çš„â€œåŸºäºå¤§æ¨¡å‹æ™ºèƒ½ä½“çš„åŠ©æ•™ç³»ç»Ÿâ€ã€‚
        ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®è¯¾å ‚æˆªå›¾ï¼Œç”Ÿæˆä¸€ä»½ç¬¦åˆã€Šç«‹é¡¹æŠ¥å‘Šã€‹æ ‡å‡†çš„ç»“æ„åŒ–å­¦ä¹ æŠ¥å‘Šã€‚
        
        ğŸš¨ **è§†è§‰æŠ—å¹²æ‰°æŒ‡ä»¤**ï¼š
        - ä¸¥ç¦åˆ†æåŒ…å« "Streamlit", "Deploy", "åŠ©æ•™æ§åˆ¶å°" å­—æ ·çš„ç•Œé¢æˆªå›¾ã€‚
        - ä¸¥ç¦åˆ†æä»£ç ç¼–è¾‘å™¨ï¼ˆVS Codeï¼‰çš„ç•Œé¢ã€‚
        - **åªåˆ†æ**å±•ç¤ºäº†è¯¾ç¨‹çŸ¥è¯†ç‚¹ï¼ˆPPTã€PDFã€æ¿ä¹¦ï¼‰çš„å›¾ç‰‡ã€‚
        
        ğŸ“ **æŠ¥å‘Šç”Ÿæˆæ ‡å‡† (å¿…é¡»ä¸¥æ ¼éµå®ˆ)**ï¼š
        
        **ç¬¬ä¸€éƒ¨åˆ†ï¼šçŸ¥è¯†ç»“æ„å›¾è°± (å¯¹åº”ç«‹é¡¹ 2.4.3)**
        - è¯·ç”¨ Markdown ç¼©è¿›åˆ—è¡¨å½¢å¼ï¼Œæ¢³ç†æœ¬èŠ‚è¯¾çš„çŸ¥è¯†å±‚çº§ç»“æ„ã€‚
        
        **ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒå†…å®¹è¯¦è§£ (å¯¹åº”ç«‹é¡¹ 2.4.4 "æœ‰æ®å¯æŸ¥")**
        - è¯¦ç»†è®²è§£ 3-5 ä¸ªæ ¸å¿ƒçŸ¥è¯†ç‚¹ã€‚
        - **å…³é”®è¦æ±‚**ï¼šæ¯è®²è§£ä¸€ä¸ªç‚¹ï¼Œå¿…é¡»æ ‡æ³¨æ¥æºè¯æ®ï¼ä¾‹å¦‚ï¼šâ€œ...æ ¹æ®[å›¾3]æ‰€ç¤ºå…¬å¼...â€ã€‚
        
        **ç¬¬ä¸‰éƒ¨åˆ†ï¼šè¾¹å­¦è¾¹æµ‹ (å¯¹åº”ç«‹é¡¹ 2.4.5)**
        - è¿™æ˜¯ç”¨æˆ·æœ€çœ‹é‡çš„åŠŸèƒ½ã€‚è¯·å¿…é¡»æ ¹æ®æœ¬èŠ‚è¯¾å†…å®¹ï¼Œå‡º **3 é“å•é¡¹é€‰æ‹©é¢˜**ã€‚
        - æ ¼å¼å¿…é¡»å¦‚ä¸‹ï¼š
          **Q1. [é¢˜ç›®å†…å®¹]**
          A. [é€‰é¡¹]  B. [é€‰é¡¹]  C. [é€‰é¡¹]  D. [é€‰é¡¹]
          > âœ… **æ­£ç¡®ç­”æ¡ˆ**ï¼šX
          > ğŸ’¡ **è§£æ**ï¼š[ä¸€å¥è¯è§£æ]
          
        **ç¬¬å››éƒ¨åˆ†ï¼šå¾…å¤ä¹ è–„å¼±ç‚¹**
        - é¢„æµ‹å­¦ç”Ÿå¯èƒ½å¬ä¸æ‡‚çš„ 1-2 ä¸ªéš¾ç‚¹ï¼Œå»ºè®®å¤ä¹ æ–¹å‘ã€‚
        """

        content_payload = []
        # å³ä½¿æ–‡å­—ä¸ºç©ºï¼Œæˆ‘ä»¬ä¹Ÿè¦å¼ºè¡Œè®© AI çœ‹å›¾
        content_payload.append({"type": "text", "text": "ã€è¯¾å ‚å½•éŸ³ã€‘ï¼š(æ— ï¼Œè¯·å…¨æƒåŸºäºæˆªå›¾åˆ†æ)\nã€è¯¾å ‚æˆªå›¾åºåˆ—ã€‘ï¼š"})

        # ç­›é€‰å›¾ç‰‡ï¼šä¸ºäº†è®©ä¹ é¢˜æ›´å‡†ï¼Œæˆ‘ä»¬ç¨å¾®å¤šå–å‡ å¼ 
        selected = image_paths[::2][:8] 
        valid_count = 0
        for i, p in enumerate(selected):
            if os.path.exists(p):
                b64 = self._encode_image(p)
                # ç»™å›¾ç‰‡ç¼–å·ï¼Œæ–¹ä¾¿ AI å¼•ç”¨
                content_payload.append({"type": "text", "text": f"[å›¾{i+1}]"})
                content_payload.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}})
                valid_count += 1
        
        if valid_count == 0:
            return "âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆæˆªå›¾ã€‚è¯·åœ¨ä¸Šè¯¾æ—¶ç¡®ä¿ç½‘è¯¾çª—å£åœ¨æœ€å‰ç«¯ã€‚"

        try:
            res = self.llm_client.chat.completions.create(
                model=LLM_ENDPOINT,
                messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": content_payload}]
            )
            return res.choices[0].message.content
        except Exception as e:
            return f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}"

    def _encode_image(self, image_path):
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

    def chat_with_context(self, question, context_text, image_paths):
        # é—®ç­”æ¨¡å¼ä¹Ÿå¯¹é½
        system_prompt = """
        ä½ æ˜¯æ™ºèƒ½åŠ©æ•™ã€‚è¯·å¿½ç•¥åŠ©æ•™æ§åˆ¶å°æˆªå›¾ã€‚
        å›ç­”é—®é¢˜æ—¶ï¼Œè¯·å°½é‡å¼•ç”¨æˆªå›¾ä½œä¸ºè¯æ®ï¼ˆä¾‹å¦‚ï¼šâ€œä½ å¯ä»¥çœ‹[å›¾2]...â€ï¼‰ã€‚
        """
        content_payload = []
        content_payload.append({"type": "text", "text": f"é—®é¢˜ï¼š{question}\næˆªå›¾è¯æ®ï¼š"})
        
        selected = image_paths[::2][:6]
        for i, p in enumerate(selected):
            if os.path.exists(p):
                b64 = self._encode_image(p)
                content_payload.append({"type": "text", "text": f"[å›¾{i+1}]"})
                content_payload.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}})

        try:
            res = self.llm_client.chat.completions.create(
                model=LLM_ENDPOINT,
                messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": content_payload}]
            )
            return res.choices[0].message.content
        except Exception as e:
            return f"âŒ å›ç­”å¤±è´¥: {e}"